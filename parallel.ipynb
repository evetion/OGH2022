{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing\n",
    "Julia has multiple ways of doing parallel computations. There's experimental multi-threading support and support for distributed computing. We'll touch upon the basics here to give you an idea what's possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threading is built-in nowadays, and we'll ignore the task part here, but go straight for speeding up computations. You can check whether this notebook actually already supports multiple threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each thread has its own id, and we can use these. Let's do it in parallel as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 2.0\n",
       " 2.0\n",
       " 3.0\n",
       " 3.0\n",
       " 4.0\n",
       " 4.0\n",
       " 5.0\n",
       " 5.0\n",
       " 6.0\n",
       " 6.0\n",
       " 7.0\n",
       " 7.0\n",
       " 8.0\n",
       " 8.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(Threads.nthreads()*2)\n",
    "Threads.@threads for i = 1:length(a)\n",
    "   a[i] = Threads.threadid()\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, threads are not simple, because you introduce so called race conditions. Each thread on its will do its thing, without synchronizing with other threads. They can all modify the same value, or read values out of order, leading to unpredictable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7405"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "@Threads.threads for i in 1:10000\n",
    "  global sum += 1\n",
    "end\n",
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can prevent this with setting the sum to be an `Atomic` entity, it should only be accessed by one thread at a time. Another way would be synchronizing, but that introduces more overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Threads.Atomic{Int64}(10000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = Threads.Atomic{Int}(0)\n",
    "@Threads.threads for i in 1:10000\n",
    "    Threads.atomic_add!(sum, 1)\n",
    "end\n",
    "sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed\n",
    "Instead of running threads, you can also run multiple Julia processes and let them communicate (or combine them).\n",
    "Threading knows about your local memory, but the next process doesn't.\n",
    "\n",
    "https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Core-or-Distributed-Processing-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add two new worker processes, which can be used for computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Int64}:\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `@distributed` macro to distribute this for loop over all worker processes. Workers make copies of the variables used in this loop. So if we want to write to the same Array on the master process, we need to use the package `SharedArrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "└ @ Main In[31]:4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x0000000119ac28c0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "\n",
    "a = SharedArray{Float64}(10)\n",
    "@info a  # empty array\n",
    "\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For longer running tasks, we can use `pmap`. It takes a function and an iterable. To use functions outside, we use @everywhere to copy these functions to all worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.741226 seconds (97.52 k allocations: 3.866 MiB, 0.61% gc time, 1.50% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100-element Vector{Int32}:\n",
       " 40089\n",
       " 40082\n",
       " 40090\n",
       " 40095\n",
       " 40086\n",
       " 40092\n",
       " 40084\n",
       " 40085\n",
       " 40087\n",
       " 40083\n",
       " 40094\n",
       " 40091\n",
       " 40121\n",
       "     ⋮\n",
       " 40165\n",
       " 40176\n",
       " 40163\n",
       " 40175\n",
       " 40172\n",
       " 40173\n",
       " 40171\n",
       " 40181\n",
       " 40178\n",
       " 40180\n",
       " 40179\n",
       " 40177"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(100)  # don't repeat this cell too much!\n",
    "\n",
    "@everywhere function slowtask(_)\n",
    "    sleep(5)\n",
    "    getpid()\n",
    "end\n",
    "\n",
    "A = rand(100)\n",
    "\n",
    "@time pmap(slowtask, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000011fa3ecb0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8 1.8.0",
   "language": "julia",
   "name": "julia-1.8-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
